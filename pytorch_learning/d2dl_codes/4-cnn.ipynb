{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Convolutional Layer from scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CNN中卷积层实际上是互相关计算，卷积的矩阵是互相关矩阵的上下、左右反转，但这无所谓，因为不管是卷积还是互相关，里面的参数都是学出来的，所以用哪种方式学出来的矩阵和输入的乘积结果都是不变的。\n",
    "\n",
    "- 特征图和感受野：对于某一filter，卷积层的输出为这个filter的特征图；感受野就是权重共享的范围，即在输出中每一像素点对应输入中决定该点值的那一个范围，范围大小为filter.shape。\n",
    "\n",
    "- 卷积层的输出不仅是h和w，还有一个channel，输出的channel是filter的个数。\n",
    "  - 若输入通道为3，输出通道为1，即用一种卷积核去卷三种输入特征的图，输出的一个特征是将三者相加\n",
    "    - 一种卷积核即（输入通道数\\*高\\*宽），在（此例中）空间上是一个立方体\n",
    "  - 若输入通道为3，输出通道为4，用4种卷积核去卷3种输入特征的图，此时卷积核的维度为：（卷积核高度、卷积核宽度、输入通道数、输出通道数（卷积核个数））一共4个,每个shape（3\\*h\\*w）\n",
    "\n",
    "- **CNN的公式**：$H_{out}=\\frac{H_{in}+2*padding-(dilation*(kernel-1)+1)}{stride}+1$\n",
    "    - 其中，$\\frac{H_{in}-kernel}{stride}+1$，可由数列推算。也可理解为：+1是因为要确保起始位置是可以的，然后再在[H_in-kernel:-1]这个区间去找，这时候向下取整，因为要确保这个位置是可以存放下kernel的，即position+kernel<[-1]\n",
    "    - 对于分母，最终得kernel size为原kernel-1（扩张的个数）\\*扩张的范围+1（最后一行/列），最终得H_in得加上padding，所以formula如上。\n",
    "    - 注意，在CNN中，卷积是向下取整，池化向上取整。\n",
    "\n",
    "- 1\\*1卷积层：输出的长宽不变，变的是channel，可以看成是在feature维度上的降维。\n",
    "\n",
    "- 一些细节：\n",
    "  - python中的sum\n",
    "    - sum(): 计算所有元素相加\n",
    "    - sum(axis=0): 计算每一列之和，返回一行\n",
    "    - sum(axis=1): 计算每一行之和，返回一列\n",
    "  - torch中的sum(input, dim, keepdim=False): dim是the dimension or dimensions to reduce，如果是1，那么就消除列，变成一列（x，1），也可以理解为在列的角度进行sum，对每一行，所有列相加。与python的sum是一样。\n",
    "  - torch.argmax()也是这样。\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The calculation of convolution\n",
    "def conv(X,Kernel):\n",
    "    h,w = Kernel.shape\n",
    "    Y = torch.zeros(X.shape[0] - h + 1, X.shape[1] - w + 1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j] = (X[i:i+h,j:j+w] * Kernel).sum()\n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "K = torch.tensor([[0, 1], [2, 3]])\n",
    "conv(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_layer()\n",
      "tensor([[-3.0843, -1.9405],\n",
      "        [ 0.3472,  1.4910]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# The layer of convolution\n",
    "class conv_layer(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(conv_layer,self).__init__()\n",
    "        self.kernel = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        Y = conv(X, self.kernel) + self.bias\n",
    "        return Y\n",
    "\n",
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "K = [2,2]  \n",
    "\n",
    "net = conv_layer(K)\n",
    "print(net)\n",
    "print(net(X))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.]])\n",
      "Y tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "# An example to perform convolution\n",
    "X = torch.ones(6, 8)\n",
    "X[:, 2:6] = 0\n",
    "print('X:',X)\n",
    "\n",
    "K = torch.tensor([[1, -1]])\n",
    "Y = conv(X, K)\n",
    "print('Y',Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step and loss 5 18.151744842529297\n",
      "step and loss 10 2.075840473175049\n",
      "step and loss 15 0.24572691321372986\n",
      "step and loss 20 0.03135181963443756\n",
      "kernel: tensor([[ 1.0017, -0.9571]])\n",
      "bias: tensor([-0.0250])\n"
     ]
    }
   ],
   "source": [
    "# Learning process for kernel parameters\n",
    "net = conv_layer(kernel_size=(1,2))\n",
    "\n",
    "step = 20\n",
    "lr = 0.01\n",
    "for i in range(step):\n",
    "    Y_hat = net(X)\n",
    "    loss = ((Y_hat-Y)**2).sum()\n",
    "    loss.backward()\n",
    "    net.kernel.data -= lr*net.kernel.grad  # use -= to keep the change\n",
    "    net.bias.data -= lr*net.bias.grad\n",
    "    \n",
    "    #net.kernel.grad.fill_(0)\n",
    "    #net.bias.grad.fill_(0)\n",
    "    net.kernel.grad.zero_()\n",
    "    net.bias.grad.zero_()\n",
    "    if (i+1) % 5 ==0:\n",
    "        print('step and loss',i+1,loss.item())\n",
    "    \n",
    "    \n",
    "print('kernel:', net.kernel.data)\n",
    "print('bias:', net.bias.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-channel in/out-put Convolutional layer from scratch\n",
    "\n",
    "- 一些细节：\n",
    "  - torch.cat与torch.stack\n",
    "    - torch.cat(tensors,dim=0,out=None)→ Tensor\n",
    "      - cat是对tensors按照指定的维度进行拼接，在该维度上叠加，返回的维度与输入的tensors的维度是一样的（输入的多个tensors维度也必须一样）\n",
    "    - torch.stack(tensors,dim=0,out=None)→ Tensor\n",
    "      - stack是在指定的位置上新开一个维度，进行拼接。\n",
    "  - torch.rand(*sizes, out=None) → Tensor\n",
    "  - torch.tensor和torch.Tensor\n",
    "    - Tensor:即torch.FloatTensor()\n",
    "      - 可以通过.float(),.long()等方法转换\n",
    "      - a = torch.Tensor()可以创建空tensor\n",
    "      - Tensor(*size)，e.g.Tensor(2,3)\n",
    "    - tensor:tensor(data)会拷贝data的数据类型\n",
    "  - PyTorch中的view的赋值是不改变内存地址的，所以view赋值的新东西永远是原来的tensor，所以view成x',y'可以view回来x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "torch.Size([2, 3])\n",
      "tensor([2, 3])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.LongTensor(2,3)\n",
    "print(a)\n",
    "print(a.size())\n",
    "\n",
    "b = torch.tensor([2,3])\n",
    "print(b)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of K and X is: torch.Size([2, 2, 2]) torch.Size([2, 3, 3])\n",
      "-------the result of multi-in conv:\n",
      "tensor([[ 56.,  72.],\n",
      "        [104., 120.]])\n",
      "torch.Size([2, 2])\n",
      "the shape of K: torch.Size([3, 2, 2, 2])\n",
      "-------the result of multi_in and multi_out:\n",
      "tensor([[[ 56.,  72.],\n",
      "         [104., 120.]],\n",
      "\n",
      "        [[ 76., 100.],\n",
      "         [148., 172.]],\n",
      "\n",
      "        [[ 96., 128.],\n",
      "         [192., 224.]]])\n",
      "torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# the size of X: (channel,highet,width) and K(out_channel,in_channel,height,width)\n",
    "\n",
    "def conv_multi_in(X,K):\n",
    "    res = conv(X[0,:,:],K[0,:,:])\n",
    "    for i in range(1,X.shape[0]):\n",
    "        res += conv(X[i,:,:],K[i,:,:])\n",
    "    return res\n",
    "\n",
    "def conv_multi_in_out(X,K):\n",
    "    return torch.stack([conv_multi_in(X,k) for k in K])\n",
    "\n",
    "X = torch.tensor([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],\n",
    "              [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "K = torch.tensor([[[0, 1], [2, 3]], [[1, 2], [3, 4]]])\n",
    "\n",
    "print('the shape of K and X is:',K.shape,X.shape)\n",
    "print('-------the result of multi-in conv:')\n",
    "print(conv_multi_in(X, K))\n",
    "print(conv_multi_in(X, K).shape)\n",
    "\n",
    "K_multi = torch.stack([K,K+1,K+2])\n",
    "print('the shape of K:',K_multi.shape)\n",
    "\n",
    "print('-------the result of multi_in and multi_out:')\n",
    "\n",
    "print(conv_multi_in_out(X,K_multi))\n",
    "print(conv_multi_in_out(X,K_multi).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 4])\n",
      "tensor([[[1, 2, 3, 4, 5, 6, 7, 8]]])\n",
      "tensor([[[1],\n",
      "         [2],\n",
      "         [3],\n",
      "         [4]],\n",
      "\n",
      "        [[5],\n",
      "         [6],\n",
      "         [7],\n",
      "         [8]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[[1,2,3,4],[5,6,7,8]]])\n",
    "print(a.size())\n",
    "b = a.view((1,1,8))\n",
    "c = b.clone().view(2,4,1)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1*1 convolution\n",
    "def conv_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.view(c_i, h * w)\n",
    "    K = K.view(c_o, c_i)\n",
    "    Y = torch.mm(K, X)  # 全连接层的矩阵乘法\n",
    "    return Y.view(c_o, h, w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling layer\n",
    "\n",
    "- 若在pooling层用stride，pooling的output为$h_{out}=f(\\frac{h_in+padding*2-kernel_size+1}{stride})$，f的意思是求上界\n",
    "\n",
    "- 一些细节\n",
    "  - pooling的时候用torch.cat，因为不需要像卷积那样将输入的通道数和kernel乘积相加，再将kernel_num个乘积重新分配在新的维度上。pooling不改变特征维度，只是对每个特征图进行operation，所以只需要cat就行，cat的dim就是通道的维度，对每个通道进行池化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.],\n",
      "        [7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "def pool2d(X, pool_size, mode='max'):\n",
    "    X = X.float()\n",
    "    h, w = X.shape\n",
    "    p_h, p_w = pool_size\n",
    "    y_h, y_w = h-p_h+1, w-p_w+1\n",
    "    y = torch.zeros(y_h,y_w)\n",
    "    for i in range(0,y_h):\n",
    "        for j in range(0,y_w):\n",
    "            if mode=='max':\n",
    "                y[i][j] = X[i:i+p_h,j:j+p_w].max()\n",
    "            elif mode=='mean':\n",
    "                y[i][j] = X[i:i+p_h,j:j+p_w].min()\n",
    "    return y\n",
    "        \n",
    "def pool2d_multi(X,pool_size,mode='max'):\n",
    "    return torch.cat(([pool2d(x,pool_size,mode) for x in X]),dim=0)\n",
    "\n",
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "print(pool2d(X,(2,2),'max'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.],\n",
      "         [ 2.,  3.],\n",
      "         [ 4.,  5.],\n",
      "         [ 6.,  7.]],\n",
      "\n",
      "        [[ 8.,  9.],\n",
      "         [10., 11.],\n",
      "         [12., 13.],\n",
      "         [14., 15.]]])\n",
      "tensor([[ 3.],\n",
      "        [ 5.],\n",
      "        [ 7.],\n",
      "        [11.],\n",
      "        [13.],\n",
      "        [15.]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float).view((2, 4, 2))\n",
    "print(X)\n",
    "print(pool2d_multi(X,(2,2),'max'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extra: stride and padding\n",
    "\n",
    "\n",
    "- stride和padding在pooling层和convolution层都有用到，这里以convolution层为背景实现。 \n",
    "- pooling的stride的default是kernel_size，padding是无"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24., 36.],\n",
       "        [72., 84.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conv_with_stride(X, Kernel, stride):\n",
    "    h,w = Kernel.shape\n",
    "    Y = torch.zeros((X.shape[0] - h) // stride + 1, (X.shape[1] - w) // stride + 1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j] = (X[i*stride:i*stride+h,j*stride:j*stride+w] * Kernel).sum()\n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15]])\n",
    "K = torch.tensor([[0, 1], [2, 3]])\n",
    "conv_with_stride(X, K, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  3.,  8., 13.,  6.],\n",
       "        [12., 24., 30., 36., 14.],\n",
       "        [28., 48., 54., 60., 22.],\n",
       "        [44., 72., 78., 84., 30.],\n",
       "        [12., 13., 14., 15.,  0.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conv_with_padding(X_old, Kernel, padding):\n",
    "    h,w = Kernel.shape\n",
    "    X = torch.zeros(X_old.shape[0]+padding*2, X_old.shape[1]+2*padding)\n",
    "    X[padding:padding+X_old.shape[0], padding:padding+X_old.shape[1]] += X_old\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j] = (X[i:i+h,j:j+w] * Kernel).sum()\n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15]])\n",
    "K = torch.tensor([[0, 1], [2, 3]])\n",
    "conv_with_padding(X, K, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs (existing networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import time\n",
    "import torch \n",
    "from torch import nn, optim\n",
    "import d2lzh_pytorch as d2dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=120, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "training on  cpu\n",
      "epoch 1, loss 1.8338, train acc 0.323, test acc 0.565, time 8.3 sec\n",
      "epoch 2, loss 0.9761, train acc 0.615, test acc 0.662, time 8.2 sec\n",
      "epoch 3, loss 0.8065, train acc 0.700, test acc 0.714, time 8.1 sec\n",
      "epoch 4, loss 0.7136, train acc 0.734, test acc 0.741, time 8.2 sec\n",
      "epoch 5, loss 0.6564, train acc 0.749, test acc 0.755, time 8.2 sec\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 256\n",
    "lr, num_epochs = 0.001, 5\n",
    "\n",
    "# Load Data\n",
    "train_iterator, test_iterator = d2dl.load_data_fashion_mnist(batch_size,root='/Users/yanzheyuan/coding/dataset_pytorch/')\n",
    "\n",
    "# Define Model\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(6,16,5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16*4*4,120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120,84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84,10)\n",
    "        )\n",
    "    def forward(self,img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0],-1))\n",
    "        return output\n",
    "\n",
    "net = LeNet()\n",
    "print(net)\n",
    "  \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "# Train Model\n",
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用。该函数将被逐步改进。\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没指定device就使用net的device\n",
    "        device = list(net.parameters())[0].device\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式, 这会关闭dropout\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train() # 改回训练模式\n",
    "            else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU\n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))\n",
    "\n",
    "\n",
    "train_ch5(net, train_iterator, test_iterator, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for X,y in train_iterator:\n",
    "    print(X.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
