{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJCJZiw0a0k9"
   },
   "source": [
    "# GoogLeNet with MNIST Dataset\n",
    "\n",
    "`Author: YUAN Yanzhe`\n",
    "\n",
    "- This notebook is a reproduction of the [GoogLeNet paper](https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Szegedy_Going_Deeper_With_2015_CVPR_paper.html).\n",
    "  - If you want to do parameter fine-tuning, setting hyperparameters on the entrance of the model is recommended.\n",
    "    - e.g. def \\_\\_init\\_\\_(param) \n",
    "- The code runs on Google Colab, GPU mode\n",
    "\n",
    "一些细节：\n",
    "- googlenet的结构，由5个block组成：\n",
    "  - 首先是一个7\\*7的conv block：conv增加feature_num和image size，pool改变image size\n",
    "  - 然后是一个conv-conv-pool的block：conv增加feature_num，pool改变image size\n",
    "  - 然后是一个incpt-incpt-pool的block\n",
    "    - incpt是inception block，每个inception block由四条通路组成在输出处cat（feature_num维度）。\n",
    "    - incpt的输出输入在image size上不变，改变的是通道数。\n",
    "  - 然后是一个incpt-incpt-incpt-incpt-pool的结构\n",
    "  - 最后是一个incpt-incpt-globalAvgPool的结构，最后的feature_num是1024\n",
    "  - 最后最后是一个flatten+fc：1024-10\n",
    "- nn.ReLU()是一个层，nn.functional.relu()是一个函数，具体怎么用看个人习惯，若要用层得在init中定义。\n",
    "- 用(96,96)的image size来训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzdWmvJtUjPb",
    "outputId": "b4fd005a-5360-4a53-eb55-a108218585fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "y1Mt4gelVllD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/MyDrive/Colab Notebooks/d2dl_pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bFElPNGHVvhY",
    "outputId": "756fbe10-effa-4290-f2b8-97bc92575d6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0+cu101\n",
      "device on: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import Packages\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.utils import data as Data\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import time\n",
    "\n",
    "import d2lzh_pytorch as d2dl\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device on:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CArWnIhJVxGX",
    "outputId": "c17f5a26-ef4f-40aa-ce01-274ae279bcf0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "googLeNet(\n",
      "  (b_1): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (b_2): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (b_3): Sequential(\n",
      "    (0): inceptionBlock(\n",
      "      (p_1_1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p_3_1): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_3_2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p_4_2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): inceptionBlock(\n",
      "      (p_1_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p_3_1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_3_2): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p_4_2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (b_4): Sequential(\n",
      "    (0): inceptionBlock(\n",
      "      (p_1_1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_1): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_2): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p_3_1): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_3_2): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p_4_2): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): inceptionBlock(\n",
      "      (p_1_1): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_2): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p_3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p_4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): inceptionBlock(\n",
      "      (p_1_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p_3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p_4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): inceptionBlock(\n",
      "      (p_1_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_1): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_2): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p_3_1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_3_2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p_4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): inceptionBlock(\n",
      "      (p_1_1): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_1): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p_3_1): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p_4_2): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (b_5): Sequential(\n",
      "    (0): inceptionBlock(\n",
      "      (p_1_1): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_1): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p_3_1): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p_4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): inceptionBlock(\n",
      "      (p_1_1): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_1): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_2_2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p_3_1): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p_3_2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p_4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): globalAvgPool()\n",
      "  )\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): inceptionBlock(\n",
      "        (p_1_1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (p_3_1): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_3_2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (p_4_2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): inceptionBlock(\n",
      "        (p_1_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (p_3_1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_3_2): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (p_4_2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): inceptionBlock(\n",
      "        (p_1_1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_1): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_2): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (p_3_1): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_3_2): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (p_4_2): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): inceptionBlock(\n",
      "        (p_1_1): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_2): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (p_3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (p_4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): inceptionBlock(\n",
      "        (p_1_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (p_3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (p_4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (3): inceptionBlock(\n",
      "        (p_1_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_1): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_2): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (p_3_1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_3_2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (p_4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (4): inceptionBlock(\n",
      "        (p_1_1): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_1): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (p_3_1): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (p_4_2): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): inceptionBlock(\n",
      "        (p_1_1): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_1): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (p_3_1): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (p_4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): inceptionBlock(\n",
      "        (p_1_1): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_1): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_2_2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (p_3_1): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (p_3_2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (p_4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (p_4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): globalAvgPool()\n",
      "    )\n",
      "  )\n",
      "  (fc_layer): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 256\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# Load Data\n",
    "# non-default argument follows default argument, has to define non-default value first\n",
    "def load_data_from_mnist(batch_size, resize=None, root=''):\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(transforms.Resize(resize))\n",
    "    trans.append(transforms.ToTensor())\n",
    "    transform = transforms.Compose(trans)\n",
    "\n",
    "    train_data = torchvision.datasets.MNIST(root=root,train=True,transform=transform,download=False)\n",
    "    test_data = torchvision.datasets.MNIST(root=root,train=False,transform=transform,download=False)\n",
    "    train_iterator = Data.DataLoader(train_data,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "    test_iterator = Data.DataLoader(test_data,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "\n",
    "    return train_iterator, test_iterator\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root=''):\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "\n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_iter, test_iter\n",
    "\n",
    "#train_iterator, test_iterator = load_data_fashion_mnist(batch_size,resize=96)\n",
    "train_iterator, test_iterator = load_data_from_mnist(batch_size,resize=96)\n",
    "\n",
    "# Define Model\n",
    "class globalAvgPool(nn.Module):\n",
    "    # the function of global average pooling is to reduce the image size to (1,1),\n",
    "    # which is convenient to reduce dimension later\n",
    "    def __init__(self):\n",
    "        super(globalAvgPool,self).__init__()\n",
    "    def forward(self, x):\n",
    "        return nn.functional.avg_pool2d(x,x.size()[2:])\n",
    "\n",
    "class inceptionBlock(nn.Module):\n",
    "    # in the inception block, there are 4 paths which use different kind of conv designs\n",
    "    # as the output of inception block the image size is remained and the feature_num is chages \n",
    "    def __init__(self, in_c, c_1, c_2, c_3, c_4):\n",
    "        super(inceptionBlock,self).__init__()\n",
    "        # the first path\n",
    "        self.p_1_1 = nn.Conv2d(in_c,c_1,1)\n",
    "        # the second path\n",
    "        self.p_2_1 = nn.Conv2d(in_c,c_2[0],1)\n",
    "        self.p_2_2 = nn.Conv2d(c_2[0],c_2[1],3,1,1)\n",
    "        # the third path\n",
    "        self.p_3_1 = nn.Conv2d(in_c,c_3[0],1)\n",
    "        self.p_3_2 = nn.Conv2d(c_3[0],c_3[1],5,1,2)\n",
    "        # the fourth path\n",
    "        self.p_4_1 = nn.MaxPool2d(3,1,1)\n",
    "        self.p_4_2 = nn.Conv2d(in_c,c_4,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p_1 = nn.functional.relu(self.p_1_1(x))\n",
    "        p_2 = nn.functional.relu(self.p_2_2(nn.functional.relu(self.p_2_1(x))))\n",
    "        p_3 = nn.functional.relu(self.p_3_2(nn.functional.relu(self.p_3_1(x))))\n",
    "        p_4 = nn.functional.relu(self.p_4_2(self.p_4_1(x)))\n",
    "        return torch.cat((p_1,p_2,p_3,p_4),dim=1)\n",
    "\n",
    "class googLeNet(nn.Module):\n",
    "    # GoogLeNet contains 5 blocks, in which contains several inception blocks.\n",
    "    def __init__(self):\n",
    "        super(googLeNet,self).__init__()\n",
    "        self.b_1 = nn.Sequential(\n",
    "            nn.Conv2d(1,64,7,2,3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.b_2 = nn.Sequential(\n",
    "            nn.Conv2d(64,64,1),\n",
    "            nn.Conv2d(64,192,3,1,1),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.b_3 = nn.Sequential(\n",
    "            inceptionBlock(192,64,(96,128),(16,32),32),\n",
    "            inceptionBlock(256, 128, (128, 192), (32, 96), 64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.b_4 = nn.Sequential(\n",
    "            inceptionBlock(480, 192, (96, 208), (16, 48), 64),\n",
    "            inceptionBlock(512, 160, (112, 224), (24, 64), 64),\n",
    "            inceptionBlock(512, 128, (128, 256), (24, 64), 64),\n",
    "            inceptionBlock(512, 112, (144, 288), (32, 64), 64),\n",
    "            inceptionBlock(528, 256, (160, 320), (32, 128), 128),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.b_5 = nn.Sequential(\n",
    "            inceptionBlock(832, 256, (160, 320), (32, 128), 128),\n",
    "            inceptionBlock(832, 384, (192, 384), (48, 128), 128),\n",
    "            globalAvgPool()\n",
    "        )\n",
    "        self.blocks = nn.Sequential(self.b_1,self.b_2,self.b_3,self.b_4,self.b_5)\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            # output layer\n",
    "            nn.Linear(1024,10),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        y = self.blocks(x)\n",
    "        y = self.fc_layer(y.view(x.shape[0],-1))  # faltten layer\n",
    "        return y\n",
    "\n",
    "net = googLeNet()\n",
    "print(net)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizor = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jU_t9faxV4Y2",
    "outputId": "903291ea-657a-48b4-f931-c0ae4037a5d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on: cuda\n",
      "testing on: cuda\n",
      "Epoch: 1, Average loss: 2.2984, Average accuracy: 12.28%, Test Accuracy: 20.80%, time: 43.3sec\n",
      "testing on: cuda\n",
      "Epoch: 2, Average loss: 1.1744, Average accuracy: 56.29%, Test Accuracy: 94.89%, time: 43.9sec\n",
      "testing on: cuda\n",
      "Epoch: 3, Average loss: 0.1318, Average accuracy: 96.28%, Test Accuracy: 97.36%, time: 44.7sec\n",
      "testing on: cuda\n",
      "Epoch: 4, Average loss: 0.0654, Average accuracy: 98.08%, Test Accuracy: 98.58%, time: 45.5sec\n",
      "testing on: cuda\n",
      "Epoch: 5, Average loss: 0.0464, Average accuracy: 98.63%, Test Accuracy: 98.10%, time: 45.8sec\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "def evaluate_model(net, test_iterator, device):\n",
    "    net = net.to(device)\n",
    "    print('testing on:', device)\n",
    "    with torch.no_grad():\n",
    "        correct,num_exp = 0.0,0\n",
    "        for X,y in test_iterator:\n",
    "            if isinstance(net, nn.Module):\n",
    "                net.eval()  # eval mode will shut off dropout function\n",
    "                correct += (net(X.to(device)).argmax(1)==y.to(device)).float().sum().cpu().item()\n",
    "                net.train()\n",
    "            else: \n",
    "                print('is this your self-defined nn module?? we are not considering GPU if so')\n",
    "                if('is_training' in net.__code__.co_varnames): \n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            num_exp += y.size(0)\n",
    "     \n",
    "    return correct/num_exp*100\n",
    "\n",
    "def train_model(num_epochs, train_iterator, test_iterator, loss_func, optimizor, net, device):\n",
    "    net = net.to(device)\n",
    "    print('training on:', device)\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss,total_batch,total_acc,total_num,start_time = 0.0,0,0.0,0,time.time()\n",
    "        for X, y in train_iterator:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            output = net(X)\n",
    "            loss = loss_func(output,y)\n",
    "            optimizor.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizor.step()\n",
    "            \n",
    "            total_loss += loss.cpu().item()\n",
    "            total_batch += 1\n",
    "            total_acc += (output.argmax(1)==y).sum().cpu().item()\n",
    "            total_num += y.size(0)\n",
    "        \n",
    "        test_acc = evaluate_model(net, test_iterator, device)\n",
    "        print('Epoch: {}, Average loss: {:.4f}, Average accuracy: {:.2f}%, Test Accuracy: {:.2f}%, time: {:.1f}sec' \\\n",
    "              .format(epoch+1, total_loss/total_batch, total_acc/total_num*100, test_acc, time.time()-start_time))\n",
    "\n",
    "train_model(num_epochs,train_iterator,test_iterator,loss_func,optimizor,net,device)\n",
    "        \n",
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1rnZxxgqgn1f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "glenet_mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
