{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regreesion\n",
    "- 逻辑回归属于分类任务，二分类任务\n",
    "- 逻辑回归采用交叉熵损失函数\n",
    "  - PyTorch中交叉熵为nn.CrossEntropyLoss(), 包含softmax在里面: https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html?highlight=nn%20crossentropyloss#torch.nn.CrossEntropyLoss\n",
    "    - torch.nn中的交叉熵为nn.LogSoftmax()+nn.NLLLoss()，前者为算出标签对应输入中的某一类的log形式的softmax（log后值域为负无穷到0）得分，后者为将该得分与label相加，求平均，取相反数（方便更新）。\n",
    "  - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy\n",
    "import d2lzh_pytorch as d2dl\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # 三维作图  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3]) torch.Size([1000])\n",
      "tensor([1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
      "Parameter containing:\n",
      "tensor([[0.0040, 0.1731, 0.4241]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0107], requires_grad=True)\n",
      "epoch 1 loss is 0.3013 accuracy is 0.9600\n",
      "\n",
      "epoch 2 loss is 0.1688 accuracy is 0.9500\n",
      "\n",
      "epoch 3 loss is 0.1225 accuracy is 0.9500\n",
      "\n",
      "epoch 4 loss is 0.0810 accuracy is 0.9800\n",
      "\n",
      "epoch 5 loss is 0.0808 accuracy is 0.9700\n",
      "\n",
      "epoch 6 loss is 0.1025 accuracy is 0.9600\n",
      "\n",
      "epoch 7 loss is 0.1198 accuracy is 0.9600\n",
      "\n",
      "epoch 8 loss is 0.0731 accuracy is 0.9600\n",
      "\n",
      "epoch 9 loss is 0.1189 accuracy is 0.9600\n",
      "\n",
      "epoch 10 loss is 0.0521 accuracy is 0.9900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate the data\n",
    "# since it is a classfication task, we need generate fake data from two distributions\n",
    "num_examples = 10000\n",
    "num_features = 3\n",
    "x_0 = torch.tensor(np.random.normal(-1,1,size=(500,num_features)),dtype=torch.float32)\n",
    "y_0 = torch.zeros(500)\n",
    "x_1 = torch.tensor(np.random.normal(1,1,size=(500,num_features)),dtype=torch.float32)\n",
    "y_1 = torch.ones(500)\n",
    "#print(x_0)\n",
    "#print(x_1)\n",
    "features = torch.cat((x_0,x_1),0)\n",
    "labels = torch.cat((y_0,y_1),0)\n",
    "print(features.size(),labels.size())\n",
    "#print(labels)\n",
    "\n",
    "\n",
    "# Visualize the data distribution\n",
    "def visualize_data_2d(features, labels):\n",
    "    d2dl.use_svg_display()\n",
    "    d2dl.set_figsize()\n",
    "    #plt.scatter(features[:,dim],labels,1)\n",
    "    plt.scatter(features.data.numpy()[:,0], features.data.numpy()[:,1], c=labels.data.numpy(), s=100, lw=0, cmap='RdYlGn')\n",
    "\n",
    "def visualize_data_3d(features, labels):\n",
    "    d2dl.use_svg_display()\n",
    "    d2dl.set_figsize()\n",
    "    ax = Axes3D(plt.figure())\n",
    "    NumP = 50\n",
    "    x = features.data.numpy()[:,0]\n",
    "    y = features.data.numpy()[:,1]\n",
    "    z = features.data.numpy()[:,2]\n",
    "    ax.scatter(x,y,z,s=40,c='r',edgecolor='k',alpha=0.5)\n",
    "\n",
    "#visualize_data_2d(features, labels)\n",
    "#visualize_data_3d(features, labels)\n",
    "\n",
    "# Data Loader & Data Batcher\n",
    "batch_size = 100\n",
    "from torch.utils import data as Data\n",
    "dataset = Data.TensorDataset(features, labels)\n",
    "data_iterator = Data.DataLoader(dataset, batch_size, shuffle=True)\n",
    "\n",
    "for X,y in data_iterator:\n",
    "    print(y)\n",
    "    break\n",
    "\n",
    "# Define Model\n",
    "from torch import nn as nn\n",
    "class Logistic_Regression_Model(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(Logistic_Regression_Model, self).__init__()\n",
    "        self.linear = nn.Linear(num_features,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        y = self.sigmoid(self.linear(x))\n",
    "        return y\n",
    "\n",
    "# instance the network\n",
    "net = Logistic_Regression_Model(num_features)\n",
    "\n",
    "# check model parameters\n",
    "for param in net.parameters():\n",
    "    print(param)\n",
    "\n",
    "# define loss function\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "# define the optimizator\n",
    "from torch import optim as optim\n",
    "optimizor = optim.SGD(net.parameters(),lr=0.03, momentum=0.9)\n",
    "\n",
    "# Training process\n",
    "# initialize the parameters\n",
    "from torch.nn import init\n",
    "init.normal_(net.linear.weight,mean=0,std=0.01)\n",
    "init.constant_(net.linear.bias,val=0)\n",
    "\n",
    "# train\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for X,y in data_iterator:\n",
    "        output = net(X)\n",
    "        #print(output)\n",
    "        loss = loss_func(output,y.view(-1,1))\n",
    "        mask = output.ge(0.5).float()\n",
    "        #mask.data = torch.tensor(1.0,dtype=torch.float32)\n",
    "        #print('y',y)\n",
    "        #print(mask)\n",
    "        correct = (mask == y.view(-1,1)).sum()\n",
    "        # print(correct)\n",
    "        accuracy = correct / X.size(0)\n",
    "        \n",
    "        optimizor.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizor.step()\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        print('epoch {} loss is {:.4f} accuracy is {:.4f}\\n'.format(epoch+1 , loss.item(), accuracy))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.nn import init\n",
    "\n",
    "import random\n",
    "import numpy\n",
    "import d2lzh_pytorch as d2dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2]) torch.Size([4, 1])\n",
      "Parameter containing:\n",
      "tensor([[ 0.5628, -0.6212]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0577], requires_grad=True)\n",
      "epoch 1 loss is 0.6794 accuracy is 0.5000\n",
      "\n",
      "epoch 2 loss is 0.6528 accuracy is 0.5000\n",
      "\n",
      "epoch 3 loss is 0.6151 accuracy is 0.5000\n",
      "\n",
      "epoch 4 loss is 0.5830 accuracy is 0.5000\n",
      "\n",
      "epoch 5 loss is 0.5648 accuracy is 0.5000\n",
      "\n",
      "epoch 6 loss is 0.5590 accuracy is 0.5000\n",
      "\n",
      "epoch 7 loss is 0.5600 accuracy is 0.5000\n",
      "\n",
      "epoch 8 loss is 0.5620 accuracy is 0.5000\n",
      "\n",
      "epoch 9 loss is 0.5613 accuracy is 0.5000\n",
      "\n",
      "epoch 10 loss is 0.5560 accuracy is 0.5000\n",
      "\n",
      "epoch 11 loss is 0.5456 accuracy is 0.5000\n",
      "\n",
      "epoch 12 loss is 0.5308 accuracy is 0.5000\n",
      "\n",
      "epoch 13 loss is 0.5130 accuracy is 0.5000\n",
      "\n",
      "epoch 14 loss is 0.4938 accuracy is 0.5000\n",
      "\n",
      "epoch 15 loss is 0.4753 accuracy is 0.7500\n",
      "\n",
      "epoch 16 loss is 0.4589 accuracy is 0.7500\n",
      "\n",
      "epoch 17 loss is 0.4458 accuracy is 0.7500\n",
      "\n",
      "epoch 18 loss is 0.4359 accuracy is 0.7500\n",
      "\n",
      "epoch 19 loss is 0.4282 accuracy is 1.0000\n",
      "\n",
      "epoch 20 loss is 0.4212 accuracy is 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Definition\n",
    "num_features = 2\n",
    "num_examples = 4\n",
    "num_epochs = 20\n",
    "\n",
    "# Generate Data\n",
    "# since it is a classfication task, we need generate fake data from two distributions\n",
    "features = torch.Tensor([[0.6,0.3], [1.0,2.5], [3.5,3.4], [4.0,5.3]])\n",
    "labels = torch.Tensor([[0.], [0.], [1.], [1.]])\n",
    "print(features.size(),labels.size())\n",
    "\n",
    "# Load Data\n",
    "# in PyTorch 0.4 Variable is disgarded, torch.Tensor combines the original function on Variable\n",
    "X = features\n",
    "y = labels\n",
    "\n",
    "# Define Model\n",
    "class Logistic_Regression_Model(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(Logistic_Regression_Model, self).__init__()\n",
    "        self.linear = nn.Linear(num_features,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        y = self.sigmoid(self.linear(x))\n",
    "        return y\n",
    "\n",
    "# instance the network\n",
    "net = Logistic_Regression_Model(num_features)\n",
    "\n",
    "# check model parameters\n",
    "for param in net.parameters():\n",
    "    print(param)\n",
    "\n",
    "# define loss function\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "# define the optimizator\n",
    "\n",
    "optimizor = optim.SGD(net.parameters(),lr=0.03, momentum=0.9)\n",
    "\n",
    "# Training process\n",
    "# initialize the parameters\n",
    "init.normal_(net.linear.weight,mean=0,std=0.01)\n",
    "init.constant_(net.linear.bias,val=0)\n",
    "\n",
    "# train\n",
    "for epoch in range(num_epochs):\n",
    "    output = net(X)\n",
    "    #print(output)\n",
    "    loss = loss_func(output,y.view(-1,1))\n",
    "    mask = output.ge(0.5).float()\n",
    "    correct = (mask == y.view(-1,1)).sum()\n",
    "    # print(correct)\n",
    "    accuracy = correct / X.size(0)\n",
    "        \n",
    "    optimizor.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizor.step()\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        print('epoch {} loss is {:.4f} accuracy is {:.4f}\\n'.format(epoch+1 , loss.item(), accuracy))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 2.2546\n",
      "Epoch [1/5], Step [200/600], Loss: 2.1804\n",
      "Epoch [1/5], Step [300/600], Loss: 2.0667\n",
      "Epoch [1/5], Step [400/600], Loss: 1.9755\n",
      "Epoch [1/5], Step [500/600], Loss: 1.8809\n",
      "Epoch [1/5], Step [600/600], Loss: 1.7587\n",
      "Epoch [2/5], Step [100/600], Loss: 1.7316\n",
      "Epoch [2/5], Step [200/600], Loss: 1.7220\n",
      "Epoch [2/5], Step [300/600], Loss: 1.6436\n",
      "Epoch [2/5], Step [400/600], Loss: 1.5120\n",
      "Epoch [2/5], Step [500/600], Loss: 1.5390\n",
      "Epoch [2/5], Step [600/600], Loss: 1.5118\n",
      "Epoch [3/5], Step [100/600], Loss: 1.4409\n",
      "Epoch [3/5], Step [200/600], Loss: 1.4115\n",
      "Epoch [3/5], Step [300/600], Loss: 1.3483\n",
      "Epoch [3/5], Step [400/600], Loss: 1.3421\n",
      "Epoch [3/5], Step [500/600], Loss: 1.2782\n",
      "Epoch [3/5], Step [600/600], Loss: 1.2524\n",
      "Epoch [4/5], Step [100/600], Loss: 1.1588\n",
      "Epoch [4/5], Step [200/600], Loss: 1.1887\n",
      "Epoch [4/5], Step [300/600], Loss: 1.2150\n",
      "Epoch [4/5], Step [400/600], Loss: 1.1469\n",
      "Epoch [4/5], Step [500/600], Loss: 1.2337\n",
      "Epoch [4/5], Step [600/600], Loss: 1.1766\n",
      "Epoch [5/5], Step [100/600], Loss: 1.1562\n",
      "Epoch [5/5], Step [200/600], Loss: 1.1003\n",
      "Epoch [5/5], Step [300/600], Loss: 1.0380\n",
      "Epoch [5/5], Step [400/600], Loss: 1.1437\n",
      "Epoch [5/5], Step [500/600], Loss: 1.0771\n",
      "Epoch [5/5], Step [600/600], Loss: 1.0174\n",
      "Accuracy of the model on the 10000 test images: 82.44999694824219 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset (images and labels)\n",
    "train_dataset = torchvision.datasets.MNIST(root='/Users/yanzheyuan/coding/dataset_pytorch/', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='/Users/yanzheyuan/coding/dataset_pytorch/', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader (input pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "# Logistic regression model\n",
    "model = nn.Linear(input_size, num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "# nn.CrossEntropyLoss() computes softmax internally\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Reshape images to (batch_size, input_size)\n",
    "        images = images.reshape(-1, 28*28)\n",
    " \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    " \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
