{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJ8JJoSclHXd"
   },
   "source": [
    "# VGGNet using MNIST Dataset\n",
    "\n",
    "`Author: YUAN Yanzhe`\n",
    "\n",
    "- This notebook is a reproduction of the [VGG paper](https://arxiv.org/abs/1409.1556).\n",
    "  - If you want to do parameter fine-tuning (like fc_layer_num, fc_hidden_layer_num: (512*7*7,4096)), setting hyperparameters on the entrance of the model is recommended.\n",
    "    - e.g. def \\_\\_init\\_\\_(param) \n",
    "- The code runs on Google Colab, GPU mode\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**一些细节：**\n",
    "- VGG的结构：\n",
    "  - vgg层，根据输入的conv_info(卷积层个数, 输入特征数, 输出特征数)循环累加vgg_block。**增加特征数**\n",
    "    - vgg_block，根据卷积层个数循环\n",
    "      - 每个循环的第一次用conv(c_in,c_out,3,1,1)。311是kernel,std,pad的组合，让特征数增加，imagede size不变\n",
    "      - 接上俩conv(c_out,c_out,3,1,1)不做改变\n",
    "      - 接上relu增加non-linearity\n",
    "    - 循环结束加上(2，2)的pool，让image的height和width减半\n",
    "  - fc层：**减少特征到10**\n",
    "    - linear-relu-dropout：减少特征数+dropout\n",
    "    - linear-relu-dropout：特征数不变+dropout\n",
    "    - output：linear降特征数到10\n",
    "      \n",
    "- AlexNet在LeNet的基础上增加了3个卷积层。但AlexNet作者对它们的卷积窗口、输出通道数和构造顺序均做了大量的调整。而VGG提出了可以通过重复使用简单的基础块来构建深度模型的思路。\n",
    "  \n",
    "- nn.Sequential 的写法：\n",
    "  - nn.Sequential(*list)\n",
    "  - nn.Sequential(nn.,nn.,...\n",
    "  - nn.Sequential(OrderedDict)\n",
    "  - net = nn.Sequential()\n",
    "    - net.addModule(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Spumefzudkr8",
    "outputId": "22f6284f-316a-4012-f703-6faf38876790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wIQU0dXMdwoM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/MyDrive/Colab Notebooks/d2dl_pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXuzeY8ed48B",
    "outputId": "f5bc71d8-b33f-4e66-b841-33dbca100fcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0+cu101\n",
      "device on: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import Packages\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.utils import data as Data\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import time\n",
    "\n",
    "import d2lzh_pytorch as d2dl\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device on:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AtSPYlgMd6ih"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 256\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# original conv_info\n",
    "#conv_info = ((1, 1, 64), (1, 64, 128), (2, 128, 256), (2, 256, 512), (2, 512, 512))\n",
    "\n",
    "conv_info = [(1, 1, 8), (1, 8, 16), (2, 16, 32), (2, 32, 64), (2, 64, 64)]\n",
    "\n",
    "# Load Data\n",
    "# non-default argument follows default argument, has to define non-default value first\n",
    "def load_data_from_mnist(batch_size, resize=None, root=''):\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(transforms.Resize(resize))\n",
    "    trans.append(transforms.ToTensor())\n",
    "    transform = transforms.Compose(trans)\n",
    "\n",
    "    train_data = torchvision.datasets.MNIST(root=root,train=True,transform=transform,download=False)\n",
    "    test_data = torchvision.datasets.MNIST(root=root,train=False,transform=transform,download=False)\n",
    "    train_iterator = Data.DataLoader(train_data,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "    test_iterator = Data.DataLoader(test_data,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "\n",
    "    return train_iterator, test_iterator\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root=''):\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "\n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_iter, test_iter\n",
    "\n",
    "#train_iterator, test_iterator = load_data_fashion_mnist(batch_size,resize=224)\n",
    "train_iterator, test_iterator = load_data_from_mnist(batch_size,resize=224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eGPDo7BoeFE_",
    "outputId": "b29216e3-450d-4fc8-821d-fbc7e33c6c42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for X,y in train_iterator:\n",
    "    print(X.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8oHkxZLieCh8",
    "outputId": "7b3c746d-5b08-4fe5-a59d-b2a981b8cf0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vggNet(\n",
      "  (vgg_layer): Sequential(\n",
      "    (vgg_block_0): Sequential(\n",
      "      (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (vgg_block_1): Sequential(\n",
      "      (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (vgg_block_2): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (vgg_block_3): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (vgg_block_4): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (fc_layer): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define Model\n",
    "class vggNet(nn.Module):\n",
    "    def __init__(self, conv_info):\n",
    "        super(vggNet,self).__init__()\n",
    "        self.vgg_layer = nn.Sequential()\n",
    "        for i, (conv_num, c_in, c_out) in enumerate(conv_info):\n",
    "            self.vgg_layer.add_module('vgg_block_'+str(i), self.vgg_block(conv_num, c_in, c_out))\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            # FNN Layer\n",
    "            nn.Linear(64*7*7,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            # Output Layer\n",
    "            nn.Linear(512,10)\n",
    "        )\n",
    "        \n",
    "    def vgg_block(self, conv_num, c_in, c_out):\n",
    "        block = []\n",
    "        for i in range(conv_num):\n",
    "            if i == 0:\n",
    "                block.append(nn.Conv2d(c_in,c_out,3,1,1))\n",
    "            else: \n",
    "                block.append(nn.Conv2d(c_out,c_out,3,1,1))\n",
    "            block.append(nn.ReLU())\n",
    "        block.append(nn.MaxPool2d(2,2))\n",
    "        return nn.Sequential(*block)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.vgg_layer(x)\n",
    "        y = self.fc_layer(y.view(x.shape[0],-1))  # faltten layer\n",
    "        return y\n",
    "\n",
    "net = vggNet(conv_info)\n",
    "print(net)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizor = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3vKAyl5IpDIf",
    "outputId": "62cafd4d-59cb-47b6-db43-35679f07a8d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on: cuda\n",
      "testing on: cuda\n",
      "Epoch: 1, Average loss: 0.5010, Average accuracy: 82.78%, Test Accuracy: 98.31%, time: 48.8sec\n",
      "testing on: cuda\n",
      "Epoch: 2, Average loss: 0.0843, Average accuracy: 97.53%, Test Accuracy: 98.73%, time: 49.2sec\n",
      "testing on: cuda\n",
      "Epoch: 3, Average loss: 0.0585, Average accuracy: 98.31%, Test Accuracy: 99.05%, time: 49.6sec\n",
      "testing on: cuda\n",
      "Epoch: 4, Average loss: 0.0468, Average accuracy: 98.67%, Test Accuracy: 99.07%, time: 50.2sec\n",
      "testing on: cuda\n",
      "Epoch: 5, Average loss: 0.0384, Average accuracy: 98.88%, Test Accuracy: 99.08%, time: 50.2sec\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "def evaluate_model(net, test_iterator, device):\n",
    "    net = net.to(device)\n",
    "    print('testing on:', device)\n",
    "    with torch.no_grad():\n",
    "        correct,num_exp = 0.0,0\n",
    "        for X,y in test_iterator:\n",
    "            if isinstance(net, nn.Module):\n",
    "                net.eval()  # eval mode will shut off dropout function\n",
    "                correct += (net(X.to(device)).argmax(1)==y.to(device)).float().sum().cpu().item()\n",
    "                net.train()\n",
    "            else: \n",
    "                print('is this your self-defined nn module?? we are not considering GPU if so')\n",
    "                if('is_training' in net.__code__.co_varnames): \n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            num_exp += y.size(0)\n",
    "     \n",
    "    return correct/num_exp*100\n",
    "\n",
    "def train_model(num_epochs, train_iterator, test_iterator, loss_func, optimizor, net, device):\n",
    "    net = net.to(device)\n",
    "    print('training on:', device)\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss,total_batch,total_acc,total_num,start_time = 0.0,0,0.0,0,time.time()\n",
    "        for X, y in train_iterator:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            output = net(X)\n",
    "            loss = loss_func(output,y)\n",
    "            optimizor.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizor.step()\n",
    "            \n",
    "            total_loss += loss.cpu().item()\n",
    "            total_batch += 1\n",
    "            total_acc += (output.argmax(1)==y).sum().cpu().item()\n",
    "            total_num += y.size(0)\n",
    "        \n",
    "        test_acc = evaluate_model(net, test_iterator, device)\n",
    "        print('Epoch: {}, Average loss: {:.4f}, Average accuracy: {:.2f}%, Test Accuracy: {:.2f}%, time: {:.1f}sec' \\\n",
    "              .format(epoch+1, total_loss/total_batch, total_acc/total_num*100, test_acc, time.time()-start_time))\n",
    "\n",
    "train_model(num_epochs,train_iterator,test_iterator,loss_func,optimizor,net,device)\n",
    "        \n",
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tg9Qh4eps11"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "vgg_mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
