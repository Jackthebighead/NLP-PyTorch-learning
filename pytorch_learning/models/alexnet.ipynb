{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUVCKwOvbqI-"
   },
   "source": [
    "# AlexNet with MNIST dataset\n",
    "\n",
    "`Author: YUAN Yanzhe`\n",
    "\n",
    "- This notebook is a reproduction of the [AlexNet paper](https://dl.acm.org/doi/pdf/10.1145/3065386).\n",
    "  - If you want to do parameter fine-tuning, setting hyperparameters on the entrance of the model is recommended.\n",
    "    - e.g. def \\_\\_init\\_\\_(param) \n",
    "- The code runs on Google Colab, GPU mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**一些细节**\n",
    "- AlexNet结构：\n",
    "  - 两层: conv-relu-pool: conv增加特征数、减小image的size，pool下采样。\n",
    "  - 三层conv, +pool: conv-relu-conv-relu-conv: 总的来说特征数不变，采用311结构让image的size不变。\n",
    "  - fc层：**减少特征到10**\n",
    "    - linear-relu-dropout：减少特征数+dropout\n",
    "    - linear-relu-dropout：特征数不变+dropout\n",
    "    - output：linear降特征数到10\n",
    "- 论文数据集是ImageNet,\n",
    "- AlexNet与LeNet的区别\n",
    "  - 层数更深\n",
    "  - 采用ReLU\n",
    "  - 采用Dropout\n",
    "  - 采用图像增广技术来扩大数据集\n",
    "    - 比如：翻转、裁剪和颜色变化\n",
    "- 可看出分类效果比LeNet好\n",
    "- trick:\n",
    "  - Conv2d(in,out,3,1,1) 保留image的hight和width，对feature_num改变\n",
    "  - MaxPool2d(2,2) 保留feature_num对image的hight和width进行减半\n",
    "- 可以用类似与这样的语句来测试网络每层输出的维度。\n",
    "for name, blk in net.named_children(): \n",
    "    X = blk(X)\n",
    "    print(name, 'output shape: ', X.shape)\n",
    "  - X = torch.rand((1, 1, 224, 224))\n",
    "  - for name, layer in net.named_children():  `named_children获取一级子模块及其名字(named_modules会返回所有子模块,包括子模块的子模块)`\n",
    "  - X = layer(X)\n",
    "  - print(name, ' output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLCgjA-mBqa9",
    "outputId": "c672a337-5c9e-43e7-c8d3-078247d8a641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WAaLyU1MBx1-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/MyDrive/Colab Notebooks/d2dl_pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lheLH1EKCC-7",
    "outputId": "af666def-c1b8-4d05-9038-b1e216bc5b4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0+cu101\n",
      "device on: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import Packages\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.utils import data as Data\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import time\n",
    "\n",
    "import d2lzh_pytorch as d2dl\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device on:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u8dRynCTC0UB",
    "outputId": "46721e17-ba18-474e-bc63-35b91051ec43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (cnn_layer): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc_layer): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 256\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# Load Data\n",
    "# non-default argument follows default argument, has to define non-default value first\n",
    "def load_data_from_mnist(batch_size, resize=None, root=''):\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(transforms.Resize(resize))\n",
    "    trans.append(transforms.ToTensor())\n",
    "    transform = transforms.Compose(trans)\n",
    "\n",
    "    train_data = torchvision.datasets.MNIST(root=root,train=True,transform=transform,download=False)\n",
    "    test_data = torchvision.datasets.MNIST(root=root,train=False,transform=transform,download=False)\n",
    "    train_iterator = Data.DataLoader(train_data,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "    test_iterator = Data.DataLoader(test_data,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "\n",
    "    return train_iterator, test_iterator\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root=''):\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "\n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_iter, test_iter\n",
    "\n",
    "#train_iterator, test_iterator = load_data_fashion_mnist(batch_size,resize=224)\n",
    "train_iterator, test_iterator = load_data_from_mnist(batch_size,resize=224)\n",
    "\n",
    "# Define Model\n",
    "class alexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(alexNet,self).__init__()\n",
    "        self.cnn_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,out_channels=96,kernel_size=11,stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            # add feature_num, remain the image size:\n",
    "            nn.Conv2d(96,256,5,1,padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3,2),\n",
    "            # three constant convolutional layer, remain the feautre_num and remain the image size:\n",
    "            nn.Conv2d(256,384,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384,384,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384,256,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            # max pool at the end:\n",
    "            nn.MaxPool2d(3,2)\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            # dropout layer, avoid overfitting\n",
    "            nn.Linear(256*5*5,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            # output layer\n",
    "            nn.Linear(4096,10),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        y = self.cnn_layer(x)\n",
    "        y = self.fc_layer(y.view(x.shape[0],-1))  # faltten layer\n",
    "        return y\n",
    "\n",
    "net = alexNet()\n",
    "print(net)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizor = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gnCXxp2ODWko",
    "outputId": "581a936e-410b-49f2-a307-5f6c4222c648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on: cuda\n",
      "testing on: cuda\n",
      "Epoch: 1, Average loss: 0.3895, Average accuracy: 86.67%, Test Accuracy: 98.39%, time: 50.2sec\n",
      "testing on: cuda\n",
      "Epoch: 2, Average loss: 0.0620, Average accuracy: 98.20%, Test Accuracy: 98.66%, time: 50.5sec\n",
      "testing on: cuda\n",
      "Epoch: 3, Average loss: 0.0453, Average accuracy: 98.63%, Test Accuracy: 99.10%, time: 50.2sec\n",
      "testing on: cuda\n",
      "Epoch: 4, Average loss: 0.0372, Average accuracy: 98.92%, Test Accuracy: 99.11%, time: 50.0sec\n",
      "testing on: cuda\n",
      "Epoch: 5, Average loss: 0.0331, Average accuracy: 99.00%, Test Accuracy: 99.11%, time: 50.0sec\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "def evaluate_model(net, test_iterator, device):\n",
    "    net = net.to(device)\n",
    "    print('testing on:', device)\n",
    "    with torch.no_grad():\n",
    "        correct,num_exp = 0.0,0\n",
    "        for X,y in test_iterator:\n",
    "            if isinstance(net, nn.Module):\n",
    "                net.eval()  # eval mode will shut off dropout function\n",
    "                correct += (net(X.to(device)).argmax(1)==y.to(device)).float().sum().cpu().item()\n",
    "                net.train()\n",
    "            else: \n",
    "                print('is this your self-defined nn module?? we are not considering GPU if so')\n",
    "                if('is_training' in net.__code__.co_varnames): \n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            num_exp += y.size(0)\n",
    "     \n",
    "    return correct/num_exp*100\n",
    "\n",
    "def train_model(num_epochs, train_iterator, test_iterator, loss_func, optimizor, net, device):\n",
    "    net = net.to(device)\n",
    "    print('training on:', device)\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss,total_batch,total_acc,total_num,start_time = 0.0,0,0.0,0,time.time()\n",
    "        for X, y in train_iterator:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            output = net(X)\n",
    "            loss = loss_func(output,y)\n",
    "            optimizor.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizor.step()\n",
    "            \n",
    "            total_loss += loss.cpu().item()\n",
    "            total_batch += 1\n",
    "            total_acc += (output.argmax(1)==y).sum().cpu().item()\n",
    "            total_num += y.size(0)\n",
    "        \n",
    "        test_acc = evaluate_model(net, test_iterator, device)\n",
    "        print('Epoch: {}, Average loss: {:.4f}, Average accuracy: {:.2f}%, Test Accuracy: {:.2f}%, time: {:.1f}sec' \\\n",
    "              .format(epoch+1, total_loss/total_batch, total_acc/total_num*100, test_acc, time.time()-start_time))\n",
    "\n",
    "train_model(num_epochs,train_iterator,test_iterator,loss_func,optimizor,net,device)\n",
    "        \n",
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VXEpOPQIQ6i7",
    "outputId": "c0f151ab-229b-4da0-abe6-7ce59eab0772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for X,y in train_iterator:\n",
    "    print(X.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5YqHM-vbgBu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwV9MHrZR8eo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "alexnet_mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
