{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN from Scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import d2lzh_pytorch as d2dl\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Data\n",
    "def load_data_jay_lyrics():\n",
    "    with open('jaychou_lyrics.txt') as f:\n",
    "        corpus_chars = f.read()\n",
    "    corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    corpus_chars = corpus_chars[0:10000]\n",
    "    idx_to_char = list(set(corpus_chars))\n",
    "    char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "    vocab_size = len(char_to_idx)\n",
    "    corpus_indices = [char_to_idx[char] for char in corpus_chars]\n",
    "    return corpus_indices, char_to_idx, idx_to_char, vocab_size\n",
    "\n",
    "(corpus_indices, char_dict, char_list, vocab_size) = load_data_jay_lyrics()\n",
    "\n",
    "# Load Data\n",
    "def data_iter_random(corpus_indices, batch_size, num_steps, device=None):\n",
    "    num_examples = len(corpus_indices) // num_steps\n",
    "    num_batch = num_examples // batch_size\n",
    "    example_list = list(range(num_examples))\n",
    "    random.shuffle(example_list)\n",
    "    \n",
    "    # obtain data in one batch\n",
    "    def _data(pos):\n",
    "        return corpus_indices[pos:pos+num_steps]\n",
    "    if device == None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    for i in range(num_batch):\n",
    "        i = i * batch_size\n",
    "        batch_indices = example_list[i:i+batch_size]\n",
    "        X = [_data(j*num_steps) for j in batch_indices]\n",
    "        Y = [_data(j*num_steps+1) for j in batch_indices]\n",
    "        yield torch.tensor(X,dtype=torch.float32,device=device), torch.tensor(Y,dtype=torch.float32,device=device)\n",
    "\n",
    "def data_iter_consecutive(corpus_indices, batch_size, num_steps, device=None):\n",
    "    if device == None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    corpus_indices = torch.tensor(corpus_indices, dtype=torch.float32, device=device)\n",
    "    batch_num = len(corpus_indices) // batch_size\n",
    "    # make a matrix over (batch_size, batch_num)\n",
    "    indices = corpus_indices[0:batch_num*batch_size].view(batch_size,batch_num)\n",
    "    # dived batch_num by num_steps to get consecutive examples\n",
    "    batch_num_example = batch_num // num_steps  \n",
    "    for i in range(batch_num_example):\n",
    "        i = i * num_steps\n",
    "        X = corpus_indices[i:i+num_steps]\n",
    "        Y = corpus_indices[i+1:i+num_steps+1]\n",
    "        yield X,Y\n",
    "    \n",
    "# Define Model\n",
    "num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size\n",
    "\n",
    "def init_rnn_state(batch_size, num_hidden, device):\n",
    "    state = torch.zeros(batch_size, num_hidden, device=device)\n",
    "    # store the inital state into a tuple\n",
    "    return (state,)\n",
    "\n",
    "def get_params():\n",
    "    def _one(shape):\n",
    "        ts = torch.tensor(np.random.normal(0,0.01,size=shape),dtype=torch.float32,device=device)\n",
    "        return nn.Parameter(ts,requires_grad=True)\n",
    "    \n",
    "    W_ih = _one((num_inputs,num_hiddens))\n",
    "    W_hh = _one((num_hiddens,num_hiddens))\n",
    "    W_ho = _one((num_hiddens,num_outputs))\n",
    "    b_h = nn.Parameter(torch.zeros(num_hiddens,device=device),requires_grad=True)\n",
    "    b_o = nn.Parameter(torch.zeros(num_outputs,device=device),requires_grad=True)\n",
    "    return nn.ParameterList([W_ih,W_hh,W_ho,b_h,b_o])\n",
    "\n",
    "def rnn(inputs, state, params):\n",
    "    W_ih,W_hh,W_ho,b_h,b_o = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.matmul(X,W_ih) + torch.matmul(H,W_hh) + b_h)\n",
    "        Y = torch.matmul(H,W_ho) + b_o\n",
    "        outputs.append(Y)\n",
    "    return outputs, (H,)\n",
    "\n",
    "def grad_clipping(params,clipping_threshold,device):\n",
    "    norm = torch.tensor([0.0], device=device)\n",
    "    for param in params:\n",
    "        norm += (param.grad.data ** 2).sum()\n",
    "    norm = norm.sqrt().item()\n",
    "    if norm > clipping_threshold:\n",
    "        for param in params:\n",
    "            param.grad.data *= (clipping_threshold / norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "def predict(prefix, num_chars, rnn, params, init_rnn_state, num_hiddens, vocab_size,\\\n",
    "                device, char_list, char_dict):\n",
    "    state = init_rnn_state(1,num_hiddens,device)\n",
    "    #print(prefix[0])\n",
    "    output = [char_dict[prefix[0]]]\n",
    "    for t in range(num_chars+len(prefix)-1):\n",
    "        X = d2dl.to_onehot(torch.tensor([[output[-1]]],device=device),vocab_size)\n",
    "        (Y,state) = rnn(X,state,params)\n",
    "        if t < len(prefix) - 1:\n",
    "            output.append(char_dict[prefix[t+1]])\n",
    "        else:\n",
    "            output.append(int(Y[0].argmax(1).item()))\n",
    "    return ''.join([char_list[i] for i in output])\n",
    "    \n",
    "    \n",
    "def train_and_predict(rnn, get_params, init_rnn_state, num_hiddens, vocab_size, device,\\\n",
    "                     corpus_indices, char_list, char_dict, is_random, num_epochs,\\\n",
    "                     num_steps, lr, clipping_theta, batch_size, pred_period, pred_len,\\\n",
    "                     prefixes, data_iter_random, data_iter_consecutive, grad_clipping):\n",
    "    if is_random:\n",
    "        data_iter_fn = data_iter_random\n",
    "    else:\n",
    "        data_iter_fn = data_iter_consecutive\n",
    "    \n",
    "    params = get_params()\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        if not is_random:\n",
    "            state = init_rnn_state(batch_size,num_hiddens,device)\n",
    "        l_sum, n = 0.0,0\n",
    "        data_iter = data_iter_fn(corpus_indices, batch_size, num_steps, device=None)\n",
    "        for X,Y in data_iter:\n",
    "            if is_random:\n",
    "                state = init_rnn_state(batch_size,num_hiddens,device)\n",
    "            else:\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "            # computation graph\n",
    "            inputs = d2dl.to_onehot(X,vocab_size)\n",
    "            (outputs,state) = rnn(inputs,state,params)\n",
    "            outputs = torch.cat(outputs,dim=0)\n",
    "            y = torch.transpose(Y,0,1).contiguous().view(-1)\n",
    "            l = loss(outputs,y.long())\n",
    "        \n",
    "            # set gradient to zero manually\n",
    "            if params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "        \n",
    "            l.backward()\n",
    "            grad_clipping(params,clipping_theta,device)\n",
    "            d2dl.sgd(params, lr, 1)  # 因为误差已经取过均值，梯度不用再做平均\n",
    "            l_sum += l.item() * y.shape[0]\n",
    "            n += y.shape[0]\n",
    "    \n",
    "        if (epoch+1) % pred_period == 0:\n",
    "            print('epoch: %d, perplexity: %f' %(epoch+1,math.exp(l_sum/n)))\n",
    "            for prefix in prefixes:\n",
    "                print('-',predict(prefix, pred_len, rnn, params, init_rnn_state,\\\n",
    "                              num_hiddens, vocab_size, device, char_list, char_dict))\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50, perplexity: 73.483295\n",
      "分\n",
      "- 分开 我不要 一九两 我给就 一九四 我什么 一九四 我什么 一颗四颗三步四 我什么 一颗两颗三颗四 我\n",
      "不\n",
      "- 不分开 我有么 一颗两颗三步四 我什么 一颗两颗三颗四 我什么 一颗两颗三颗四 我什么 一颗两颗三颗四 我\n",
      "epoch: 100, perplexity: 10.561730\n",
      "分\n",
      "- 分开 有一个人 在使用双截棍 哼哼哈兮 快使用双截棍 哼哼哈兮 快使用双截棍 哼哼哈兮 快使用双截棍 哼\n",
      "不\n",
      "- 不分开吗 我不想我想你 你你想觉 我已好这生活 后知后觉 我该好这生活 后知后觉 我该好这生活 后知后觉 \n",
      "epoch: 150, perplexity: 2.905499\n",
      "分\n",
      "- 分开 有亮底 一颗两步三步四颗 连成线背著背默默许下心愿 看远方的星是否听的见 还牵灌 一步两步三步四步\n",
      "不\n",
      "- 不分开扫 我后你的 你在后真 你却没用 不够不痛 你不懂 连不知的你 一阵莫名 恨你在美太 你一定烛抽 仙\n",
      "epoch: 200, perplexity: 1.617301\n",
      "分\n",
      "- 分开 沙亮开 告诉我 印地 是术完闷  所底梦  你爱一起热粥 没伤了  如果我想 你不作爸不嘛 我知后\n",
      "不\n",
      "- 不分开期 我叫你爸 你打我妈 这样对吗了嘛这样 我不下神之你许愿知道好  我的世界已狂风暴雨 Wu 看不你\n",
      "epoch: 250, perplexity: 1.323383\n",
      "分\n",
      "- 分开 沙杰开不 我有了带节 巫的事空 我想要 我情走 你怎么 但分怎 三沉丹田 心头之中 最上心动 染红\n",
      "不\n",
      "- 不分开期把的胖女巫 用拉丁文念咒语啦啦呜 她养的黑猫笑起来像哭 啦啦啦呜 一根我不 我被店爸恼  没有你烦\n"
     ]
    }
   ],
   "source": [
    "num_epochs, num_steps, batch_size, lr, clipping_theta = 250, 35, 32, 1e2, 1e-2\n",
    "pred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']\n",
    "\n",
    "train_and_predict(rnn, get_params, init_rnn_state, num_hiddens,\n",
    "                      vocab_size, device, corpus_indices, char_list,\n",
    "                      char_dict, True, num_epochs, num_steps, lr,\n",
    "                      clipping_theta, batch_size, pred_period, pred_len,\n",
    "                      prefixes,data_iter_random,data_iter_consecutive,grad_clipping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Data\n",
    "(corpus_indices, char_dict, char_list, vocab_size) = load_data_jay_lyrics()\n",
    "\n",
    "# Define Model\n",
    "rnn_layer = nn.RNN(vocab_size,hidden_size)\n",
    "class rnnModel(nn.Module):\n",
    "    def __init__(self, rnn_layer, vocab_size):\n",
    "        super(rnnModel,self).__init__()\n",
    "        self.rnn = rnn_layer()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
