{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla RNN\n",
    "`Author: YUAN Yanzhe`\n",
    "\n",
    "- This notebook contains:\n",
    "  - RNN Language Model from scratch\n",
    "  - RNN Language Model using PyTorch\n",
    "- Dataset: Jaychou's Lyrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN LM from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import d2lzh_pytorch as d2dl\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Data\n",
    "def load_data_jay_lyrics():\n",
    "    with open('jaychou_lyrics.txt') as f:\n",
    "        corpus_chars = f.read()\n",
    "    corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    corpus_chars = corpus_chars[0:10000]\n",
    "    idx_to_char = list(set(corpus_chars))\n",
    "    char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "    vocab_size = len(char_to_idx)\n",
    "    corpus_indices = [char_to_idx[char] for char in corpus_chars]\n",
    "    return corpus_indices, char_to_idx, idx_to_char, vocab_size\n",
    "\n",
    "(corpus_indices, char_dict, char_list, vocab_size) = load_data_jay_lyrics()\n",
    "\n",
    "# Load Data\n",
    "def data_iter_random(corpus_indices, batch_size, num_steps, device=None):\n",
    "    num_examples = len(corpus_indices) // num_steps\n",
    "    num_batch = num_examples // batch_size\n",
    "    example_list = list(range(num_examples))\n",
    "    random.shuffle(example_list)\n",
    "    \n",
    "    # obtain data in one batch\n",
    "    def _data(pos):\n",
    "        return corpus_indices[pos:pos+num_steps]\n",
    "    if device == None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    for i in range(num_batch):\n",
    "        i = i * batch_size\n",
    "        batch_indices = example_list[i:i+batch_size]\n",
    "        X = [_data(j*num_steps) for j in batch_indices]\n",
    "        Y = [_data(j*num_steps+1) for j in batch_indices]\n",
    "        yield torch.tensor(X,dtype=torch.float32,device=device), torch.tensor(Y,dtype=torch.float32,device=device)\n",
    "\n",
    "def data_iter_consecutive(corpus_indices, batch_size, num_steps, device=None):\n",
    "    if device == None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    corpus_indices = torch.tensor(corpus_indices, dtype=torch.float32, device=device)\n",
    "    batch_num = len(corpus_indices) // batch_size\n",
    "    # make a matrix over (batch_size, batch_num)\n",
    "    indices = corpus_indices[0:batch_num*batch_size].view(batch_size,batch_num)\n",
    "    # dived batch_num by num_steps to get consecutive examples\n",
    "    batch_num_example = batch_num // num_steps  \n",
    "    for i in range(batch_num_example):\n",
    "        i = i * num_steps\n",
    "        X = corpus_indices[:,i:i+num_steps]\n",
    "        Y = corpus_indices[:,i+1:i+num_steps+1]\n",
    "        yield X,Y\n",
    "    \n",
    "# Define Model\n",
    "num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size\n",
    "\n",
    "def init_rnn_state(batch_size, num_hidden, device):\n",
    "    state = torch.zeros(batch_size, num_hidden, device=device)\n",
    "    # store the inital state into a tuple\n",
    "    return (state,)\n",
    "\n",
    "def get_params():\n",
    "    def _one(shape):\n",
    "        ts = torch.tensor(np.random.normal(0,0.01,size=shape),dtype=torch.float32,device=device)\n",
    "        return nn.Parameter(ts,requires_grad=True)\n",
    "    \n",
    "    W_ih = _one((num_inputs,num_hiddens))\n",
    "    W_hh = _one((num_hiddens,num_hiddens))\n",
    "    W_ho = _one((num_hiddens,num_outputs))\n",
    "    b_h = nn.Parameter(torch.zeros(num_hiddens,device=device),requires_grad=True)\n",
    "    b_o = nn.Parameter(torch.zeros(num_outputs,device=device),requires_grad=True)\n",
    "    return nn.ParameterList([W_ih,W_hh,W_ho,b_h,b_o])\n",
    "\n",
    "def rnn(inputs, state, params):\n",
    "    W_ih,W_hh,W_ho,b_h,b_o = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.matmul(X,W_ih) + torch.matmul(H,W_hh) + b_h)\n",
    "        Y = torch.matmul(H,W_ho) + b_o\n",
    "        outputs.append(Y)\n",
    "    return outputs, (H,)\n",
    "\n",
    "def grad_clipping(params,clipping_threshold,device):\n",
    "    norm = torch.tensor([0.0], device=device)\n",
    "    for param in params:\n",
    "        norm += (param.grad.data ** 2).sum()\n",
    "    norm = norm.sqrt().item()\n",
    "    if norm > clipping_threshold:\n",
    "        for param in params:\n",
    "            param.grad.data *= (clipping_threshold / norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "def predict(prefix, num_chars, rnn, params, init_rnn_state, num_hiddens, vocab_size,\\\n",
    "                device, char_list, char_dict):\n",
    "    state = init_rnn_state(1,num_hiddens,device)\n",
    "    #print(prefix[0])\n",
    "    output = [char_dict[prefix[0]]]\n",
    "    for t in range(num_chars+len(prefix)-1):\n",
    "        X = d2dl.to_onehot(torch.tensor([[output[-1]]],device=device),vocab_size)\n",
    "        (Y,state) = rnn(X,state,params)\n",
    "        if t < len(prefix) - 1:\n",
    "            output.append(char_dict[prefix[t+1]])\n",
    "        else:\n",
    "            output.append(int(Y[0].argmax(1).item()))\n",
    "    return ''.join([char_list[i] for i in output])\n",
    "    \n",
    "    \n",
    "def train_and_predict(rnn, get_params, init_rnn_state, num_hiddens, vocab_size, device,\\\n",
    "                     corpus_indices, char_list, char_dict, is_random, num_epochs,\\\n",
    "                     num_steps, lr, clipping_theta, batch_size, pred_period, pred_len,\\\n",
    "                     prefixes, data_iter_random, data_iter_consecutive, grad_clipping):\n",
    "    if is_random:\n",
    "        data_iter_fn = data_iter_random\n",
    "    else:\n",
    "        data_iter_fn = data_iter_consecutive\n",
    "    \n",
    "    params = get_params()\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        if not is_random:\n",
    "            state = init_rnn_state(batch_size,num_hiddens,device)\n",
    "        l_sum, n = 0.0,0\n",
    "        data_iter = data_iter_fn(corpus_indices, batch_size, num_steps, device=None)\n",
    "        for X,Y in data_iter:\n",
    "            if is_random:\n",
    "                state = init_rnn_state(batch_size,num_hiddens,device)\n",
    "            else:\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "            # computation graph\n",
    "            inputs = d2dl.to_onehot(X,vocab_size)\n",
    "            (outputs,state) = rnn(inputs,state,params)\n",
    "            outputs = torch.cat(outputs,dim=0)\n",
    "            y = torch.transpose(Y,0,1).contiguous().view(-1)\n",
    "            l = loss(outputs,y.long())\n",
    "        \n",
    "            # set gradient to zero manually\n",
    "            if params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "        \n",
    "            l.backward()\n",
    "            grad_clipping(params,clipping_theta,device)\n",
    "            d2dl.sgd(params, lr, 1)  # 因为误差已经取过均值，梯度不用再做平均\n",
    "            l_sum += l.item() * y.shape[0]\n",
    "            n += y.shape[0]\n",
    "    \n",
    "        if (epoch+1) % pred_period == 0:\n",
    "            print('epoch: %d, perplexity: %f' %(epoch+1,math.exp(l_sum/n)))\n",
    "            for prefix in prefixes:\n",
    "                print('-',predict(prefix, pred_len, rnn, params, init_rnn_state,\\\n",
    "                              num_hiddens, vocab_size, device, char_list, char_dict))\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50, perplexity: 67.967254\n",
      "- 分开 我不要再想 我不能再不 我不能再想 我不能再不 我不能再想 我不能再不 我不能再想 我不能再不 我\n",
      "- 不分开  我不要再不 我不要我想 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 \n",
      "epoch: 100, perplexity: 10.108797\n",
      "- 分开 我想想好生 我不 我不 我不要再想你 不知不觉 你已经离开我 不知不觉 我跟了这节奏 我知道好生你\n",
      "- 不分开吗 我已你再想 我不能再想 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 \n",
      "epoch: 150, perplexity: 2.956918\n",
      "- 分开 有不想好起 我唱往再的 我有能有  我有 这不跟久了吧? 折一枝杨柳 你在那有 在小村外的溪边河口\n",
      "- 不分开吗 我不能再想 我不 我不 我不能 爱情走的太快就像龙卷风 不能承受我已无处可躲 我不要再想 我不能\n",
      "epoch: 200, perplexity: 1.569537\n",
      "- 分开 有蟑段不起 谁辛都美 全家怕日出 白色蜡烛 温暖了空屋 白色蜡烛 温暖了空屋 白色蜡烛 温暖了空屋\n",
      "- 不分开想 我不能再想 我不 我不 我不能再想你 不知不觉 你已经离开我 不知不觉 我跟了这节奏 后知后觉 \n",
      "epoch: 250, perplexity: 1.319545\n",
      "- 分开 有蟑想 教拳脚武术的老板 练铁沙掌 耍杨家枪 硬底子功 过目种种 象一场梦 不敢去碰 没有梦痛 不\n",
      "- 不分开期 我叫你爸 你打我妈 这样对吗干嘛这样 何必让酒牵鼻子B 瞎 说着三么我对妈 难说你 不颗我抬起头\n"
     ]
    }
   ],
   "source": [
    "num_epochs, num_steps, batch_size, lr, clipping_theta = 250, 35, 32, 1e2, 1e-2\n",
    "pred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']\n",
    "\n",
    "train_and_predict(rnn, get_params, init_rnn_state, num_hiddens,\n",
    "                      vocab_size, device, corpus_indices, char_list,\n",
    "                      char_dict, True, num_epochs, num_steps, lr,\n",
    "                      clipping_theta, batch_size, pred_period, pred_len,\n",
    "                      prefixes,data_iter_random,data_iter_consecutive,grad_clipping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN LM using PyTorch\n",
    "\n",
    "一些细节\n",
    "- 目标：实现语言模型\n",
    "- 使用RNN模型之前\n",
    "  - 定义dataloader-采样\n",
    "    - 在随机采样中，每个样本是原始序列上任意截取的一段序列。相邻的两个随机小批量在原始序列上的位置不一定相毗邻。因此，我们无法用一个小批量最终时间步的隐藏状态来初始化下一个小批量的隐藏状态。在训练模型时，每次随机采样前都需要重新初始化隐藏状态。\n",
    "      - 这样我们对于每个batch都得初始化，因为batch之间并不连续无法保存上下文\n",
    "    - 令相邻的batch在原始序列上的位置相邻。我们可以用一个batch的最终隐藏状态来初始化下一个batch的隐藏状态，从而使下一个小批量的输出也取决于当前小批量的输入，并如此循环下去。\n",
    "      - 这样，我们只需对每个epoch进行初始化\n",
    "      - 但是为了避免梯度累积在每个batch要detach一下state\n",
    "  - 将数据转换成合适的格式，包括one-hot，转换成embedding，数据采样归化batches等等，如果batch内的example不同长，还需要pack。\n",
    "    - 处理不定长输入（即每个batch的num_steps不定长）\n",
    "      - 用`torch.nn.utils.rnn.PackedSequence`\n",
    "      - https://zhuanlan.zhihu.com/p/49486149, https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence\n",
    "- 定义RNN模型\n",
    "  - 数据也需要转换，包括cat，stack等\n",
    "  - RNN层定义的时候需要定义input_size, hidden_size等，在调用的时候RNN层的输入是inputs, state, 输出是outputs，state。\n",
    "    - inputs的size是(num_steps, batch_size, input_size)\n",
    "    - state是初始化的hidden state: (num_layers * num_directions, batch, hidden_size)\n",
    "    - outputs的size是(num_steps, batch_size, hidden_size)，如果是bidirection的话hidden_size要乘上bi\n",
    "    - state的size是(num_layers * num_direction, batch_size, hidden_size)，如果是stacked RNN，那么第一维为num_layer。\n",
    "  - RNN能伸能张：RNN模块结构的num_steps时间步和batch_size都是根据实际输入来改变的，所以我们定义的RNN模型可以作为一个sequence RNN来用，也可以作为一个RNN单位。\n",
    "- 训练\n",
    "  - **训练过程**\n",
    "    - 定义loss(y要为longTensor)和optimizor(Adam)\n",
    "    - 初始化state，model转为device\n",
    "    - 对每个epoch开始循环：\n",
    "      - 从data loader中提取1 batch的X和Y\n",
    "        - 若为consecutive每个batch提取后与上一次的分离\n",
    "        - 模型输出，计算loss\n",
    "        - 梯度清零，反向传播，梯度裁剪，优化器更新\n",
    "        - 计算统计量\n",
    "      - 一个epoch结束，输出统计量，若满足条件，开始predict/test\n",
    "  - 训练过程细节\n",
    "    - 初始状态可以不定义（None）\n",
    "    - d2dl.grad_clipping\n",
    "- 测试\n",
    "  - 根据prefix来预测pred_len个输出。\n",
    "  - 上一个字符的输出作为下一个的输入。\n",
    "  - RNN能伸能张：RNN模块结构的num_steps时间步和batch_size都是根据实际输入来改变的，所以我们定义的RNN模型可以作为一个sequence RNN来用，也可以作为一个RNN单位。当我们用作一个单位时（即输入num_step为1），我们可以用单位RNN的输出作为下一个的输入，这样整个就是一个sequence RNN，而state也能保持一直以来的信息。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import d2lzh_pytorch as d2dl\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnnModel(\n",
      "  (rnn_layer): RNN(1027, 256)\n",
      "  (dense_layer): Linear(in_features=256, out_features=1027, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Obtain Data\n",
    "def load_data_jay_lyrics():\n",
    "    with open('jaychou_lyrics.txt') as f:\n",
    "        corpus_chars = f.read()\n",
    "    corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    corpus_chars = corpus_chars[0:10000]\n",
    "    idx_to_char = list(set(corpus_chars))\n",
    "    char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "    vocab_size = len(char_to_idx)\n",
    "    corpus_indices = [char_to_idx[char] for char in corpus_chars]\n",
    "    return corpus_indices, char_to_idx, idx_to_char, vocab_size\n",
    "\n",
    "(corpus_indices, char_dict, char_list, vocab_size) = load_data_jay_lyrics()\n",
    "input_size, hidden_size = vocab_size, 256\n",
    "\n",
    "# Load Data: batches\n",
    "def dataloader_consecutive(corpus_indices, batch_size, num_steps, device=device):\n",
    "    # the same as data_iter_consecutive\n",
    "    corpus_indices = torch.tensor(corpus_indices,dtype=torch.float32,device=device)\n",
    "    corpus_len = len(corpus_indices)\n",
    "    num_batch = corpus_len // batch_size\n",
    "    indices = corpus_indices[0:batch_size*num_batch].view(batch_size,num_batch)\n",
    "    num_batch_exmp = (num_batch-1) // num_steps  # consideration of Y\n",
    "    for i in range(num_batch_exmp):\n",
    "        i  = i * num_steps\n",
    "        X = indices[:,i:i+num_steps]\n",
    "        Y = indices[:,i+1:i+1+num_steps]\n",
    "        yield X, Y\n",
    "\n",
    "# Define Model\n",
    "class rnnModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(rnnModel,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.state = None  # initial hidden state can be None\n",
    "        self.rnn_layer = nn.RNN(input_size,hidden_size)\n",
    "        self.dense_layer = nn.Linear(hidden_size,input_size)\n",
    "    def forward(self, inputs, state):\n",
    "        # inputs: (batch_size, num_step)\n",
    "        x = d2dl.to_onehot(inputs,self.input_size)  # x: list(num_step*(batch_size, input_size))\n",
    "        y, self.state = self.rnn_layer(torch.stack(x),state)  # y: (num_step, batch_size, hidden_size)\n",
    "        output = self.dense_layer(y.view(-1,y.shape[-1]))  # output: (num_step, batch_size, hidden_size)\n",
    "        return output, self.state\n",
    "\n",
    "net = rnnModel(input_size,hidden_size).to(device)\n",
    "print(net)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Model\n",
    "def predict_lm(prefix, pred_len, net, vocab_size, device, char_dict, char_list):\n",
    "    outputs = [char_dict[prefix[0]]]\n",
    "    state = None\n",
    "    for i in range(pred_len+len(prefix)-1):\n",
    "        # initialization\n",
    "        inputs = torch.tensor([outputs[-1]],device=device).view(1,1)  # (batch_size, num_step)= (1,1)\n",
    "        if state is not None:\n",
    "            if isinstance(state,tuple):\n",
    "                state = (state[0].to(divice), state[1].to(device))  # LSTM state: (h,c)\n",
    "            else:\n",
    "                state = state.to(device)\n",
    "        \n",
    "        (Y, state) = net(inputs, state)\n",
    "        \n",
    "        if i < len(prefix)-1:\n",
    "            outputs.append(char_dict[prefix[i+1]])\n",
    "        else: \n",
    "            outputs.append(int(Y.argmax(1).item()))  # argmax returns index\n",
    "    return ''.join([char_list[item] for item in outputs])\n",
    "        \n",
    "#predict_lm('分', 20, net, vocab_size, device, char_dict, char_list)\n",
    "\n",
    "# Train Model: consecutive sampling\n",
    "def train_lm(model, num_hiddens, vocab_size, device, corpus_indices, char_list, char_dict,\\\n",
    "            num_epochs, num_steps, lr, clipping_theta, batch_size, pred_period, pred_len, prefixes):\n",
    "    # define loss and optimizor\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizor = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    state = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        state=None\n",
    "        l_sum, n, start = 0.0, 0, time.time()\n",
    "        data_iter = dataloader_consecutive(corpus_indices,batch_size,num_steps,device)\n",
    "        for X, Y in data_iter:  # X:(batch_size, num_step), Y:(batch_size, num_step)\n",
    "            # consecutive sampling requires detach at each batch to reduce computation on grads.\n",
    "            if state is not None:\n",
    "                if isinstance(state,tuple):\n",
    "                    state = (state[0].detach(),state[1].detach())\n",
    "                else:\n",
    "                    state = state.detach()\n",
    "        \n",
    "            # modeling\n",
    "            (outputs, state) = model(X, state)  # outputs: (num_step*batch_size,output_size)\n",
    "            y = torch.transpose(Y,0,1).contiguous().view(-1)  # y: (num_step*batch_size)\n",
    "            l = loss(outputs,y.long())\n",
    "        \n",
    "            # bp\n",
    "            optimizor.zero_grad()\n",
    "            l.backward()\n",
    "            d2dl.grad_clipping(model.parameters(),clipping_theta,device)  \n",
    "            optimizor.step()\n",
    "        \n",
    "            # stats\n",
    "            l_sum += l.item()\n",
    "            n += 1\n",
    "        \n",
    "        try:\n",
    "            perplexity = math.exp(l_sum/n)\n",
    "        except OverflowError:\n",
    "            perplexity = float('inf')\n",
    "            \n",
    "        if (epoch+1) % pred_period == 0:  # predict after pred_period time\n",
    "            print('epoch %d, perplexity %f, time %.2f sec'%(epoch+1, perplexity, \\\n",
    "                                                                time.time()-start))\n",
    "            for prefix in prefixes:\n",
    "                print('-', predict_lm(prefix, pred_len, net, vocab_size, device, \\\n",
    "                                          char_dict, char_list))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, perplexity 1.011058, time 0.47 sec\n",
      "- 分开的了口被废拆封 誓言太沉重泪被纵容 脸上汹涌失控 穿梭时间的画面的钟 从反方向开始移动 回到当初爱你\n",
      "- 不分开不了我 难过 是因为闷了很久 是因为想了太多 是心理起了作用 你说 苦笑常常陪着你 在一起有点勉强 \n",
      "epoch 100, perplexity 1.008328, time 0.54 sec\n",
      "- 分开的了口 老慢再 原 用楔形文字刻下了永远 那已风化千年的誓言 一切又重演 我感到很疲倦离家乡还是很远\n",
      "- 不分开不了我 娘子 你在我了多年 它一直在身边 干什么 干什么 我打开任督二脉 干什么 干什么 东亚病夫的\n",
      "epoch 150, perplexity 1.008404, time 0.52 sec\n",
      "- 分开 我笑常不知不  不知不觉 你已经离开我 不知不觉 我跟了这节奏 后知后觉 又过了一个秋 后知后觉 \n",
      "- 不分开不了我 能回到你身边 我给你的爱写在西元前 深埋在美索不达米亚平原 几十个世纪后出土发现 泥板上的字\n",
      "epoch 200, perplexity 1.008087, time 0.47 sec\n",
      "- 分开的玩笑 想通 却又再考倒我 说散 你想很久了吧? 败给你的黑色幽默 说散 你想很久了吧? 我的认真败\n",
      "- 不分开不了我 不知不觉 我跟了这节奏 后知后觉 后知后觉 迷迷蒙蒙 你给的梦 出现裂缝 隐隐作痛 怎么沟通\n",
      "epoch 250, perplexity 1.007815, time 0.50 sec\n",
      "- 分开的玩笑 想通 却又再考倒我 说散 你想很久了吧? 败给你的黑色幽默 不想太多 我想一定是我听错弄错搞\n",
      "- 不分开不了我 谁你看透 的就像是童话没有 在别人有 难熬  什么都到过得很不会呵护著你 这样 甜蜜 让我开\n"
     ]
    }
   ],
   "source": [
    "# Main:\n",
    "num_steps = 32\n",
    "num_epochs, batch_size, lr, clipping_theta = 250, 32, 1e-3, 1e-2 # 注意这里的学习率设置\n",
    "pred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']\n",
    "train_lm(net, hidden_size, vocab_size, device, corpus_indices, char_list, char_dict,\\\n",
    "        num_epochs, num_steps, lr, clipping_theta, batch_size, pred_period, pred_len, prefixes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
